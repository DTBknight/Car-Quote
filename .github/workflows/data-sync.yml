name: 分布式品牌爬虫数据同步

on:
  schedule:
    # 每周一凌晨0点 (UTC时间)
    - cron: '0 0 * * 1'
  workflow_dispatch: # 允许手动触发
    inputs:
      target_brands:
        description: '指定要爬取的品牌（用空格分隔，如：BYD Tesla BMW，留空则爬取所有品牌）'
        required: false
        default: ''
      max_concurrent:
        description: '最大并发数（1-5）'
        required: false
        default: '3'
        type: choice
        options:
        - '1'
        - '2'
        - '3'
        - '4'
        - '5'

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      brands: ${{ steps.setup.outputs.brands }}
      concurrent: ${{ steps.setup.outputs.concurrent }}
    steps:
    - name: 设置爬虫参数
      id: setup
      run: |
        if [ -n "${{ github.event.inputs.target_brands }}" ]; then
          echo "brands=${{ github.event.inputs.target_brands }}" >> $GITHUB_OUTPUT
        else
          echo "brands=all" >> $GITHUB_OUTPUT
        fi
        echo "concurrent=${{ github.event.inputs.max_concurrent || '3' }}" >> $GITHUB_OUTPUT

  sync:
    runs-on: ubuntu-latest
    needs: setup
    concurrency:
      group: data-sync
      cancel-in-progress: false
    permissions:
      contents: write
      pull-requests: write
      actions: write
      checks: write
    
    steps:
    - name: 检出代码
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
      
    - name: 设置Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
        cache-dependency-path: data-processor/package-lock.json
        
    - name: Install Chrome Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y wget gnupg2 jq
        wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
        
    - name: Install Dependencies
      run: |
        cd data-processor
        npm ci
        
    - name: 生成品牌爬虫文件
      run: |
        cd data-processor
        echo "🏭 生成品牌爬虫文件..."
        node generate-brand-crawlers.js
        echo "✅ 品牌爬虫文件生成完成"
        
    - name: 执行分布式品牌爬虫
      run: |
        cd data-processor
        echo "🚀 开始执行分布式品牌爬虫系统..."
        echo "📅 执行时间: $(date '+%Y-%m-%d %H:%M:%S')"
        echo "🔧 使用工具: 分布式品牌爬虫调度器 v3.0"
        echo "🎯 目标品牌: ${{ needs.setup.outputs.brands }}"
        echo "⚡ 最大并发: ${{ needs.setup.outputs.concurrent }}"
        
        # 根据输入参数决定执行方式
        if [ "${{ needs.setup.outputs.brands }}" = "all" ]; then
          echo "📊 运行所有118个品牌爬虫..."
          node brand-scheduler.js
        else
          echo "📊 运行指定品牌爬虫: ${{ needs.setup.outputs.brands }}"
          node brand-scheduler.js ${{ needs.setup.outputs.brands }}
        fi
        
        echo "✅ 分布式爬虫任务完成"
      env:
        NODE_ENV: production
        PUPPETEER_SKIP_CHROMIUM_DOWNLOAD: true
        PUPPETEER_EXECUTABLE_PATH: /usr/bin/google-chrome-stable
        CRAWLER_MAX_CONCURRENT: ${{ needs.setup.outputs.concurrent }}
      timeout-minutes: 480
        
    - name: 验证分布式爬虫结果
      run: |
        set -e
        cd data-processor
        echo "🔍 验证分布式爬虫结果..."
        
        # 验证品牌爬虫系统配置
        echo "📋 检查分布式爬虫系统..."
        if [ -f "brand-scheduler.js" ]; then
          echo "✅ 品牌调度器存在"
        fi
        if [ -f "brand-crawler-template.js" ]; then
          echo "✅ 品牌爬虫模板存在"
        fi
        if [ -d "brand-crawlers" ]; then
          crawler_count=$(ls brand-crawlers/*.js 2>/dev/null | wc -l)
          echo "✅ 品牌爬虫文件数量: $crawler_count"
        fi
        
        # 验证调度器执行结果
        if [ -f "logs/scheduler/report-$(date '+%Y-%m-%d').json" ]; then
          echo "✅ 调度器报告文件存在"
        fi
        
        # 验证数据文件
        echo "📊 验证数据文件..."
        if [ -f "scripts/validate.js" ]; then
          node scripts/validate.js
        else
          echo "ℹ️ 数据验证脚本不存在，跳过验证"
        fi
        
        echo "✅ 分布式爬虫结果验证完成"
        
    - name: 生成执行报告
      run: |
        set -e
        cd data-processor
        
        echo "## 🚀 分布式品牌爬虫执行结果" >> $GITHUB_STEP_SUMMARY
        echo "- 执行时间: $(date '+%Y-%m-%d %H:%M:%S')" >> $GITHUB_STEP_SUMMARY
        echo "- 目标品牌: ${{ needs.setup.outputs.brands }}" >> $GITHUB_STEP_SUMMARY
        echo "- 并发设置: ${{ needs.setup.outputs.concurrent }}" >> $GITHUB_STEP_SUMMARY
        
        # 显示新爬虫系统信息
        echo "## 🔧 分布式爬虫系统信息" >> $GITHUB_STEP_SUMMARY
        echo "- 系统版本: 分布式品牌爬虫 v3.0" >> $GITHUB_STEP_SUMMARY
        echo "- 核心特性:" >> $GITHUB_STEP_SUMMARY
        echo "  - 🏗️ 品牌独立爬虫架构（118个独立爬虫）" >> $GITHUB_STEP_SUMMARY
        echo "  - ⚡ 智能并发调度和负载均衡" >> $GITHUB_STEP_SUMMARY
        echo "  - 🔄 品牌级别失败隔离和自动重试" >> $GITHUB_STEP_SUMMARY
        echo "  - 📊 实时监控和详细日志记录" >> $GITHUB_STEP_SUMMARY
        echo "  - 🎯 品牌专属配置优化" >> $GITHUB_STEP_SUMMARY
        echo "  - 🛡️ 超时保护和资源管理" >> $GITHUB_STEP_SUMMARY
        
        # 查找调度器报告
        latest_scheduler_report=$(ls -t logs/scheduler/report-*.json 2>/dev/null | head -1)
        if [ -n "$latest_scheduler_report" ]; then
          echo "## 📊 调度器执行详情" >> $GITHUB_STEP_SUMMARY
          echo "- 调度器报告: $latest_scheduler_report" >> $GITHUB_STEP_SUMMARY
          
          if command -v jq > /dev/null; then
            success_rate=$(jq -r '.summary.successRate' "$latest_scheduler_report" 2>/dev/null || echo "N/A")
            completed=$(jq -r '.summary.completed' "$latest_scheduler_report" 2>/dev/null || echo "N/A")
            total=$(jq -r '.summary.total' "$latest_scheduler_report" 2>/dev/null || echo "N/A")
            duration=$(jq -r '.totalDuration' "$latest_scheduler_report" 2>/dev/null || echo "N/A")
            
            echo "- 成功率: $success_rate" >> $GITHUB_STEP_SUMMARY
            echo "- 完成品牌: $completed/$total" >> $GITHUB_STEP_SUMMARY
            echo "- 总耗时: $duration" >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "## ⚠️ 调度器状态" >> $GITHUB_STEP_SUMMARY
          echo "- 调度器报告文件未找到" >> $GITHUB_STEP_SUMMARY
        fi
        
        # 统计数据文件
        data_files=$(ls -1 ../data/*.json 2>/dev/null | grep -v brands.json | wc -l)
        echo "## 📁 数据文件统计" >> $GITHUB_STEP_SUMMARY
        echo "- 品牌数据文件: $data_files 个" >> $GITHUB_STEP_SUMMARY
        
        # 统计品牌日志
        if [ -d "logs/brands" ]; then
          brand_logs=$(ls -1 logs/brands/*.json 2>/dev/null | wc -l)
          echo "- 品牌日志文件: $brand_logs 个" >> $GITHUB_STEP_SUMMARY
        fi
        
    - name: 提交更新
      run: |
        set -e
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        
        echo "添加数据文件..."
        git add data/*.json || true
        
        echo "添加分布式爬虫日志和报告..."
        git add -f data-processor/logs/scheduler/*.json || true
        git add -f data-processor/logs/brands/*.json || true
        git add -f data-processor/status/*.json || true
        
        if git diff --staged --quiet; then
          echo "没有变更需要提交"
        else
          git commit -m "🚀 分布式品牌爬虫数据更新 - $(date '+%Y-%m-%d') [目标: ${{ needs.setup.outputs.brands }}]"
          git pull origin main --rebase --autostash
          git push origin HEAD:main
        fi